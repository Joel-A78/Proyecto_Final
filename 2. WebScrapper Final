"""
Plebes, este webscraper ya tiene para que extraiga dos tablas, si siguen con la misma
lógica nomás agreguen los links de las otras tablas que quieran agregar
"""

import time
import pandas as pd
import mysql.connector
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import os

def crear_driver():
    opciones = Options()
    opciones.add_argument("--window-size=1920,1080")
    opciones.add_argument("--headless")  # Opcional: si no quieres que abra ventana
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=opciones)

def guardar(df, nombre_tabla):
    try:
        conn = mysql.connector.connect(
            host="127.0.0.2",
            user="root",
            password="12345678",
            database="f1"
        )
        cursor = conn.cursor()

        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {nombre_tabla} (
                id INT AUTO_INCREMENT PRIMARY KEY,
                piloto VARCHAR(100),
                valor INT,
                pista VARCHAR(100)
            )
        """)
        cursor.execute(f"DELETE FROM {nombre_tabla}")

        for _, row in df.iterrows():
            cursor.execute(f"""
                INSERT INTO {nombre_tabla} (piloto, valor, pista)
                VALUES (%s, %s, %s)
            """, (row["Piloto"], row["Valor"], row["Pista"]))

        conn.commit()
        print(f"Datos guardados en MySQL: {nombre_tabla}")
    except Exception as e:
        print("Error al guardar en MySQL:", e)
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def guardar_csv(df, nombre_tabla):
    carpeta = "PF"
    os.makedirs(carpeta, exist_ok=True)
    ruta_csv = os.path.join(carpeta, f"{nombre_tabla}.csv")
    df.to_csv(ruta_csv, index=False, encoding="utf-8")
    print(f"CSV guardado: {ruta_csv}")

def tabla(url, nombre_tabla):
    driver = crear_driver()
    wait = WebDriverWait(driver, 15)

    try:
        driver.get(url)
        tabla = wait.until(EC.presence_of_element_located((By.ID, "ctl00_CPH_Main_GV_Stats")))
        filas = tabla.find_elements(By.XPATH, ".//tbody/tr")

        datos = []
        for fila in filas:
            celdas = fila.find_elements(By.TAG_NAME, "td")
            texto_celdas = [celda.text.strip().replace(" ", "") for celda in celdas]

            if len(texto_celdas) == 3:
                datos.append(texto_celdas)
            elif len(texto_celdas) == 4:
                datos.append(texto_celdas[1:])  # Ignorar número (columna 0)

        df = pd.DataFrame(datos, columns=["Piloto", "Valor", "Pista"])
        df["Valor"] = pd.to_numeric(df["Valor"], errors="coerce")

        guardar(df, nombre_tabla)
        guardar_csv(df, nombre_tabla)

    except Exception as e:
        print(f"Error al procesar {url}:", e)
    finally:
        driver.quit()

if __name__ == "__main__":
    tabla(
        url="https://www.statsf1.com/es/statistiques/pilote/victoire/nombre.aspx",
        nombre_tabla="victorias_totales"
    )
    tabla(
        url="https://www.statsf1.com/es/statistiques/pilote/meilleurtour/grandprix.aspx",
        nombre_tabla="vueltas_rapidas"
    )
    tabla(
        url="https://www.statsf1.com/es/statistiques/pilote/victoire/circuit.aspx",
        nombre_tabla="victorias_por_circuito"
    )
